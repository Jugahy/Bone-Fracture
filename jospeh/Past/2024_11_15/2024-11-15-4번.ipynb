{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "# import tensorflow as tf2\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "session = tf1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f19fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras import backend as K  # 추가된 부분\n",
    "from tensorflow.keras import layers  # Conv2D, MaxPooling2D 등 일부를 layers에서 가져올 수도 있습니다\n",
    "\n",
    "def open_image(image_dir, image_file):\n",
    "    \"\"\"\n",
    "    주어진 디렉터리와 파일명을 사용하여 이미지를 읽고, Grayscale 형식으로 변환합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image_dir (str): 이미지 파일이 저장된 디렉터리 경로.\n",
    "    - image_file (str): 읽을 이미지 파일 이름.\n",
    "    \n",
    "    반환값:\n",
    "    - Grayscale로 변환된 이미지 (numpy.ndarray).\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(image_dir, image_file)  # 디렉터리와 파일 이름을 결합하여 이미지 경로 생성\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2GRAY)  # 이미지 읽고 Grayscale로 변환\n",
    "\n",
    "\n",
    "def visualize_width_image(images):\n",
    "    \"\"\"\n",
    "    여러 이미지를 가로로 출력합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - images (list): 시각화할 이미지의 리스트.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5 * len(images), 5))  # 이미지 갯수에 따라 가로 크기 조정\n",
    "    for idx, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), idx + 1)  # 가로로 이미지를 나란히 출력\n",
    "        plt.imshow(image, cmap='gray')  # Grayscale 형식으로 이미지 출력\n",
    "        plt.axis('off')  # 축 비활성화\n",
    "    plt.show()  # 시각화 출력\n",
    "\n",
    "\n",
    "def visualize_hight_image(images):\n",
    "    \"\"\"\n",
    "    여러 이미지를 세로로 출력합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - images (list): 시각화할 이미지의 리스트.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 5 * len(images)))  # 이미지 갯수에 따라 세로 크기 조정\n",
    "    for idx, image in enumerate(images):\n",
    "        plt.subplot(len(images), 1, idx + 1)  # 세로로 이미지를 나란히 출력\n",
    "        plt.imshow(image, cmap='gray')  # Grayscale 형식으로 이미지 출력\n",
    "        plt.axis('off')  # 축 비활성화\n",
    "    plt.show()  # 시각화 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "    훈련 및 검증 정확도와 손실을 시각화합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - history: 정확도 및 손실 값을 포함하는 훈련 기록 객체.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # 정확도 그래프\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Model Accuracy')\n",
    "\n",
    "    # 손실 그래프\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('에포크(Epoch)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Model Loss')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_f1_score(model, x_val, y_val, batch_size=4):\n",
    "    \"\"\"\n",
    "    F1 점수를 계산하고 출력합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - model: 검증 데이터 세트에서 예측을 생성할 훈련된 모델.\n",
    "    - x_val: 검증 데이터 입력값.\n",
    "    - y_val: 검증 데이터 레이블.\n",
    "    - batch_size: 예측을 위한 배치 크기(기본값: 4).\n",
    "    \n",
    "    반환값:\n",
    "    - y_pred: 예측된 레이블.\n",
    "    - y_true: 실제 레이블.\n",
    "    \"\"\"\n",
    "    y_pred = np.argmax(model.predict(x_val, batch_size=batch_size), axis=-1)\n",
    "    y_true = np.argmax(y_val, axis=-1)\n",
    "\n",
    "    f1 = f1_score(y_true.flatten(), y_pred.flatten(), average='weighted')\n",
    "    print(f\"F1 점수: {f1:.2f}\")\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def plot_confusion_matrix_with_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    혼동 행렬을 시각화하고 정밀도, 재현율, F1 점수를 출력합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - y_true: 실제 레이블.\n",
    "    - y_pred: 예측된 레이블.\n",
    "    \"\"\"\n",
    "    # Flatten 데이터\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    \n",
    "    # 혼동 행렬 계산\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # 메트릭 계산 (zero_division=0 설정)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # 메트릭 출력\n",
    "    print(\"=== 성능 지표 ===\")\n",
    "    print(f\"정밀도(Precision): {precision:.2f}\")\n",
    "    print(f\"재현율(Recall): {recall:.2f}\")\n",
    "    \n",
    "    # 혼동 행렬 시각화\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_true_vs_pred_images(model, x_val, y_val, num_images=5, batch_size=4):\n",
    "    \"\"\"\n",
    "    실제 이미지, 라벨 이미지 및 예측된 이미지를 나란히 시각화합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - model: 검증 데이터 세트에서 예측을 생성할 훈련된 모델.\n",
    "    - x_val: 검증 데이터 입력값.\n",
    "    - y_val: 검증 데이터 레이블.\n",
    "    - num_images: 시각화할 이미지 수 (기본값: 5).\n",
    "    - batch_size: 예측을 위한 배치 크기(기본값: 4).\n",
    "    \"\"\"\n",
    "    # 예측 생성\n",
    "    y_pred = model.predict(x_val, batch_size=batch_size)\n",
    "    \n",
    "    plt.figure(figsize=(25, 3 * num_images))\n",
    "    for i in range(num_images):\n",
    "        # 실제 입력 이미지\n",
    "        plt.subplot(num_images, 5, 5 * i + 1)\n",
    "        plt.imshow(x_val[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 실제 라벨 이미지 (첫 번째 채널 선택 - 전경)\n",
    "        plt.subplot(num_images, 5, 5 * i + 2)\n",
    "        plt.imshow(y_val[i][..., 1].squeeze(), cmap='gray')  # 전경 채널 시각화\n",
    "        plt.title('Label Image (Foreground)')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 예측된 이미지 (전체 클래스 비교 - argmax로 클래스 라벨 선택)\n",
    "        plt.subplot(num_images, 5, 5 * i + 3)\n",
    "        plt.imshow(np.argmax(y_val[i], axis=-1).squeeze(), cmap='gray')\n",
    "        plt.title('Original Label (Argmax)')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 예측된 이미지 (첫 번째 채널 선택 - 전경)\n",
    "        plt.subplot(num_images, 5, 5 * i + 4)\n",
    "        plt.imshow(y_pred[i][..., 1].squeeze(), cmap='gray')  # 전경 채널 시각화\n",
    "        plt.title('Predicted Image (Foreground)')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 예측된 이미지 (전체 클래스 비교 - argmax로 클래스 라벨 선택)\n",
    "        plt.subplot(num_images, 5, 5 * i + 5)\n",
    "        plt.imshow(np.argmax(y_pred[i], axis=-1).squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Label (Argmax)')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def main_display_result(history, model, x_val, y_val, batch_size=4, num_images=5):\n",
    "    \"\"\"\n",
    "    전체 워크플로우 실행: 정확도/손실 그래프 시각화, F1 점수 계산, 혼동 행렬 및 메트릭 출력, 실제/예측 이미지 비교.\n",
    "    \n",
    "    매개변수:\n",
    "    - history: 정확도 및 손실 값을 포함하는 훈련 기록 객체.\n",
    "    - model: 검증 데이터 세트에서 예측을 생성할 훈련된 모델.\n",
    "    - x_val: 검증 데이터 입력값.\n",
    "    - y_val: 검증 데이터 레이블.\n",
    "    - batch_size: 예측을 위한 배치 크기(기본값: 4).\n",
    "    - num_images: 시각화할 이미지 수 (기본값: 5).\n",
    "    \"\"\"\n",
    "    # 훈련 및 검증 정확도/손실 그래프 시각화\n",
    "    plot_accuracy_loss(history)\n",
    "    \n",
    "    # F1 점수 계산 및 예측값 반환\n",
    "    y_true, y_pred = calculate_f1_score(model, x_val, y_val, batch_size=batch_size)\n",
    "    \n",
    "    # 혼동 행렬 및 메트릭 출력\n",
    "    plot_confusion_matrix_with_metrics(y_true, y_pred)\n",
    "    \n",
    "    # 실제 이미지와 예측된 이미지 비교 시각화\n",
    "    plot_true_vs_pred_images(model, x_val, y_val, num_images=num_images, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(json_path):\n",
    "    \"\"\"\n",
    "    JSON 데이터를 불러옵니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - json_path (str): JSON 파일의 경로.\n",
    "    \n",
    "    반환값:\n",
    "    - json_data (dict): JSON 데이터로 파싱된 Python 딕셔너리 객체.\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        json_data = json.load(f)  # JSON 파일 읽기 및 파싱\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "def get_polygon_from_json(json_data, image_filename):\n",
    "    \"\"\"\n",
    "    JSON 데이터에서 특정 이미지에 대한 다각형(Polygon) 데이터를 추출합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - json_data (dict): JSON에서 로드된 데이터.\n",
    "    - image_filename (str): 다각형 정보를 추출할 이미지 파일 이름.\n",
    "    \n",
    "    반환값:\n",
    "    - polygons (list): 다각형의 x, y 좌표 리스트 [(x_coords, y_coords), ...].\n",
    "    \"\"\"\n",
    "    regions = json_data[image_filename][\"regions\"]  # 이미지와 관련된 영역 정보 가져오기\n",
    "    polygons = []  # 다각형 정보를 저장할 리스트\n",
    "    \n",
    "    for region_id, region_info in regions.items():  # 영역 정보 순회\n",
    "        shape_attributes = region_info[\"shape_attributes\"]  # 모양 정보 추출\n",
    "        if shape_attributes[\"name\"] == \"polygon\":  # 다각형인지 확인\n",
    "            x_coords = shape_attributes[\"all_points_x\"]  # x 좌표\n",
    "            y_coords = shape_attributes[\"all_points_y\"]  # y 좌표\n",
    "            polygons.append((x_coords, y_coords))  # 다각형 정보 추가\n",
    "    \n",
    "    return polygons\n",
    "\n",
    "\n",
    "def creat_mask(image):\n",
    "    \"\"\"\n",
    "    주어진 이미지 크기에 따라 빈 마스크 이미지를 생성합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image (numpy.ndarray): 원본 이미지.\n",
    "    \n",
    "    반환값:\n",
    "    - image (numpy.ndarray): 동일한 크기의 빈 마스크 이미지 (값이 0으로 초기화된 배열).\n",
    "    \"\"\"\n",
    "    image = np.zeros(image.shape)  # 이미지 크기와 동일한 배열 생성 (0으로 초기화)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def fill_polygons(image, polygons):\n",
    "    \"\"\"\n",
    "    빈 마스크 이미지에 다각형 영역을 채웁니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image (numpy.ndarray): 빈 마스크 이미지.\n",
    "    - polygons (list): 다각형의 x, y 좌표 리스트 [(x_coords, y_coords), ...].\n",
    "    \n",
    "    반환값:\n",
    "    - image (numpy.ndarray): 다각형이 채워진 마스크 이미지.\n",
    "    \"\"\"\n",
    "    image = image.copy()  # 원본 이미지를 복사하여 수정\n",
    "    for x_coords, y_coords in polygons:  # 다각형 리스트 순회\n",
    "        pts = np.array([list(zip(x_coords, y_coords))], dtype=np.int32)  # 좌표를 다각형 형태로 변환\n",
    "        cv2.fillPoly(image, pts, color=255)  # 다각형 내부를 흰색(255)으로 채움\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def crate_mask_image(image_dir, json_path, image_file):\n",
    "    \"\"\"\n",
    "    이미지와 JSON 데이터를 기반으로 다각형이 채워진 마스크 이미지를 생성합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image_dir (str): 원본 이미지 파일이 저장된 디렉터리 경로.\n",
    "    - json_path (str): 다각형 정보를 포함하는 JSON 파일의 경로.\n",
    "    - image_file (str): 처리할 이미지 파일 이름.\n",
    "    \n",
    "    반환값:\n",
    "    - mask_image (numpy.ndarray): 생성된 마스크 이미지.\n",
    "    \"\"\"\n",
    "    json_data = open_json(json_path)  # JSON 데이터 로드\n",
    "    image = open_image(image_dir, image_file)  # 원본 이미지 로드\n",
    "    \n",
    "    mask_image = creat_mask(image)  # 빈 마스크 이미지 생성\n",
    "                       \n",
    "    return fill_polygons(mask_image, get_polygon_from_json(json_data, image_file))  # 다각형을 마스크에 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, shape):\n",
    "    \"\"\"\n",
    "    입력된 이미지의 크기를 지정된 shape로 조정합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image (numpy.ndarray): 크기 조정할 이미지.\n",
    "    - shape (tuple): 조정할 크기 (높이, 너비).\n",
    "    \n",
    "    반환값:\n",
    "    - resized_image (numpy.ndarray): 조정된 크기의 이미지.\n",
    "    \n",
    "    주의: 항상 채널 차원이 추가된 이미지를 반환합니다.\n",
    "    \"\"\"\n",
    "    resized_image = cv2.resize(image, shape)  # 입력 이미지의 크기를 지정된 shape로 조정\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def expand_dims(image):\n",
    "    \"\"\"\n",
    "    입력된 이미지를 채널 차원(axis=-1)까지 확장합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image (numpy.ndarray): 채널 차원을 확장할 이미지.\n",
    "    \n",
    "    반환값:\n",
    "    - expanded_image (numpy.ndarray): 채널 차원이 추가된 이미지.\n",
    "    \"\"\"\n",
    "    expanded_image = np.expand_dims(image, axis=-1)  # 이미지를 채널 차원까지 확장\n",
    "    return expanded_image\n",
    "\n",
    "def prepare_and_count_labels(y_train, y_val):\n",
    "    \"\"\"\n",
    "    주어진 레이블 데이터(y_train, y_val)에 대해 0과 1로 이진화하고, 각 레이블의 빈도를 출력합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - y_train (numpy.ndarray): 학습 데이터 레이블.\n",
    "    - y_val (numpy.ndarray): 검증 데이터 레이블.\n",
    "    \n",
    "    반환값:\n",
    "    - y_train.shape (tuple): 학습 레이블 크기.\n",
    "    - y_val.shape (tuple): 검증 레이블 크기.\n",
    "    \"\"\"\n",
    "    # 이진화: 0보다 큰 값을 1로, 0은 그대로 0으로 설정\n",
    "    y_train = np.where(y_train > 0, 1, 0)\n",
    "    y_val = np.where(y_val > 0, 1, 0)\n",
    "    \n",
    "    # y_train의 값별 빈도 계산\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    value_counts = dict(zip(unique, counts))\n",
    "    \n",
    "    # 빈도 출력\n",
    "    print(\"학습 데이터셋 레이블 빈도:\")\n",
    "    for value, count in value_counts.items():\n",
    "        print(f\"값: {value}, 빈도: {count}\")\n",
    "    \n",
    "    # y_val의 값별 빈도 계산\n",
    "    unique, counts = np.unique(y_val, return_counts=True)\n",
    "    value_counts = dict(zip(unique, counts))\n",
    "    \n",
    "    # 빈도 출력\n",
    "    print(\"검증 데이터셋 레이블 빈도:\")\n",
    "    for value, count in value_counts.items():\n",
    "        print(f\"값: {value}, 빈도: {count}\")\n",
    "    \n",
    "    return y_train, y_val\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    이미지를 정규화하여 0에서 1 사이의 값으로 변환합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - image (numpy.ndarray): 정규화할 이미지 배열.\n",
    "    \n",
    "    반환값:\n",
    "    - normalized_image (numpy.ndarray): 정규화된 이미지 배열.\n",
    "    \"\"\"\n",
    "    normalized_image = image.astype(np.float32) / 255.0\n",
    "    return normalized_image\n",
    "\n",
    "def add_background_channel(mask):\n",
    "    \"\"\"\n",
    "    마스크에서 배경 채널을 추가합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - mask (numpy.ndarray): 단일 채널 마스크 (0: 배경, 1: 객체).\n",
    "    \n",
    "    반환값:\n",
    "    - multi_channel_mask (numpy.ndarray): 2채널 마스크 (채널 0: 배경, 채널 1: 객체).\n",
    "    \"\"\"\n",
    "    background = 1 - mask  # 배경 채널은 객체 채널의 반전값\n",
    "    multi_channel_mask = np.stack([background, mask], axis=-1)  # 채널 축으로 쌓음\n",
    "    return multi_channel_mask\n",
    "\n",
    "def regularize_mask(mask):\n",
    "    \"\"\"\n",
    "    생성된 마스크 이미지를 정규화하여 잡음을 제거하고 품질을 개선합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - mask (numpy.ndarray): 생성된 마스크 이미지.\n",
    "    \n",
    "    반환값:\n",
    "    - regularized_mask (numpy.ndarray): 정규화된 마스크 이미지.\n",
    "    \"\"\"\n",
    "    # Gaussian Blur로 잡음 제거\n",
    "    blurred = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    \n",
    "    # Binary Threshold 적용\n",
    "    _, binary = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Morphological Transformations (열림 연산)으로 작은 잡음 제거\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def prepare_dataset(image_dir, json_path, image_size=(512, 512), test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    주어진 이미지 디렉토리와 JSON 파일로부터 데이터를 준비하고 학습/검증 데이터셋을 반환합니다.\n",
    "    데이터 내 0과 1 이외의 값이 포함된 경우 이진화 처리 및 빈도 계산을 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - image_dir (str): 이미지가 저장된 디렉터리 경로.\n",
    "    - json_path (str): 폴리곤 마스크 정보가 포함된 JSON 파일 경로.\n",
    "    - image_size (tuple): 이미지 크기 조정할 크기 (기본값: (512, 512)).\n",
    "    - test_size (float): 테스트 데이터 비율 (기본값: 0.2).\n",
    "    - random_state (int): 랜덤 상태 (기본값: 42).\n",
    "\n",
    "    반환값:\n",
    "    - x_train (numpy.ndarray): 학습 이미지.\n",
    "    - x_val (numpy.ndarray): 검증 이미지.\n",
    "    - y_train (numpy.ndarray): 학습 이미지 마스크 (2채널).\n",
    "    - y_val (numpy.ndarray): 검증 이미지 마스크 (2채널).\n",
    "    \"\"\"\n",
    "    image = []\n",
    "    image_mask = []\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith('.jpg'):  # 이미지 파일만 처리\n",
    "            # 이미지와 마스크 데이터를 크기 조정 및 채널 차원 확장\n",
    "            img = np.expand_dims(image_resize(open_image(image_dir, image_file), image_size), axis=-1)\n",
    "            img = normalize_image(img)  # 이미지 정규화\n",
    "            image.append(img)\n",
    "\n",
    "            # 마스크 생성 및 크기 조정\n",
    "            mask = image_resize(crate_mask_image(image_dir, json_path, image_file), image_size)\n",
    "            \n",
    "            # 정규화 과정 적용\n",
    "            mask = regularize_mask(mask)\n",
    "            \n",
    "            # 채널 차원 추가 및 이진화\n",
    "            mask = np.expand_dims(mask, axis=-1)\n",
    "            mask = np.where(mask > 0, 1, 0)  # 이진화\n",
    "            \n",
    "            # 배경 채널 추가\n",
    "            mask = add_background_channel(mask)\n",
    "            image_mask.append(mask)\n",
    "\n",
    "    # NumPy 배열로 변환\n",
    "    image = np.array(image)\n",
    "    image_mask = np.array(image_mask)\n",
    "\n",
    "    # 학습용과 검증용 데이터로 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(image, image_mask, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # y_train과 y_val에서 0과 1 외의 값이 포함되어 있는지 확인\n",
    "    unique_train = np.unique(y_train)\n",
    "    unique_val = np.unique(y_val)\n",
    "\n",
    "    if len(set(unique_train) - {0, 1}) > 0 or len(set(unique_val) - {0, 1}) > 0:\n",
    "        print(\"경고: 레이블에 0과 1 이외의 값이 포함되어 있습니다. 레이블 준비를 수행합니다.\")\n",
    "        y_train, y_val = prepare_and_count_labels(y_train, y_val)\n",
    "    else:\n",
    "        print(\"레이블이 이미 이진화되어 있습니다 (0과 1만 포함).\")\n",
    "\n",
    "    # 크기 확인 및 불일치 시 처리\n",
    "    x_train = np.squeeze(x_train)\n",
    "    x_val = np.squeeze(x_val)\n",
    "    y_train = np.squeeze(y_train)\n",
    "    y_val = np.squeeze(y_val)\n",
    "\n",
    "    # 크기 출력\n",
    "    print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")\n",
    "\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'FracAtlas/images/Fractured'\n",
    "json_path = 'FracAtlas/Annotations/VGG JSON/VGG_fracture_masks.json'\n",
    "\n",
    "x_train, x_val, y_train, y_val = prepare_dataset(image_dir, json_path, image_size=(512, 512), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51139661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# U-Net 모델 정의\n",
    "def unet_model(input_shape, num_classes=2):\n",
    "    \"\"\"\n",
    "    U-Net 모델 정의 함수.\n",
    "    \n",
    "    매개변수:\n",
    "    - input_shape: 입력 이미지 형태 (높이, 너비, 채널).\n",
    "    - num_classes: 출력 채널 수. 기본값은 2 (배경과 객체).\n",
    "\n",
    "    반환값:\n",
    "    - Keras 모델 객체.\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    # Decoder\n",
    "    u2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u2 = concatenate([u2, c2])\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u1 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u1 = concatenate([u1, c1])\n",
    "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c5)  # num_classes에 따라 출력 채널 설정\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# EarlyStopping 콜백 정의 (IoU를 기준으로 모니터링)\n",
    "def early_stopping_iou_callback(weight=1.0):\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_weighted_iou',   # IoU를 모니터링\n",
    "        patience=3,                  # 개선이 없을 때 기다릴 에포크 수\n",
    "        restore_best_weights=True,   # 가장 좋은 모델의 가중치를 복원\n",
    "        mode='max',                  # IoU 값이 최대일 때 성능이 좋은 것으로 간주\n",
    "    )\n",
    "    return early_stopping\n",
    "\n",
    "# Focal Loss 정의 (레이블 불균형 대응)\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
    "    return loss_fn\n",
    "\n",
    "# Jaccard Index (IoU) 계산 함수 정의\n",
    "def iou(y_true, y_pred, smooth=1e-4):\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "    y_true = K.argmax(y_true, axis=-1)\n",
    "    y_true = K.cast(y_true, dtype='float32')\n",
    "    y_pred = K.cast(y_pred, dtype='float32')\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=(1, 2))\n",
    "    union = K.sum(y_true, axis=(1, 2)) + K.sum(y_pred, axis=(1, 2)) - intersection\n",
    "    iou_score = (intersection + smooth) / (union + smooth)\n",
    "    return K.mean(iou_score)\n",
    "\n",
    "# 모델 컴파일 (IoU 및 Focal Loss)\n",
    "def compile_model_with_focal_loss(model, weight=1.0):\n",
    "    def weighted_iou(y_true, y_pred):\n",
    "        iou_score = iou(y_true, y_pred)\n",
    "        return iou_score * weight  # IoU에 가중치를 곱함\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss=focal_loss(alpha=0.25, gamma=2.0),  # Focal Loss 사용\n",
    "        metrics=['accuracy', weighted_iou]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 데이터 증강 적용 및 입력 데이터 차원 조정\n",
    "def augment_data(x_train, y_train, batch_size=4):\n",
    "    \"\"\"\n",
    "    데이터 증강을 수행하고 입력 데이터 차원을 확인 및 수정합니다.\n",
    "    \"\"\"\n",
    "    # 입력 데이터 차원 확장\n",
    "    if x_train.ndim == 3:\n",
    "        x_train = np.expand_dims(x_train, axis=-1)  # (batch_size, height, width) -> (batch_size, height, width, 1)\n",
    "    if y_train.ndim == 3:\n",
    "        y_train = np.expand_dims(y_train, axis=-1)  # 동일하게 채널 차원 추가\n",
    "\n",
    "    # 데이터 증강 생성기\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # 데이터 제너레이터 생성\n",
    "    generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    return generator\n",
    "\n",
    "# 데이터 증강 적용 및 입력 데이터 차원 조정\n",
    "    \"\"\"\n",
    "    데이터 증강을 수행합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - x_train (numpy.ndarray): 학습 이미지 데이터.\n",
    "    - y_train (numpy.ndarray): 학습 레이블 데이터.\n",
    "    \n",
    "    반환값:\n",
    "    - generator: 증강된 데이터를 생성하는 데이터 제너레이터.\n",
    "    \"\"\"\n",
    "    # 입력 데이터 차원 확장\n",
    "    if x_train.ndim == 3:\n",
    "        x_train = np.expand_dims(x_train, axis=-1)\n",
    "    if y_train.ndim == 3:\n",
    "        y_train = np.expand_dims(y_train, axis=-1)\n",
    "\n",
    "    # 데이터 증강 생성기\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # 데이터 제너레이터 생성\n",
    "    generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    return generator\n",
    "\n",
    "# 모델 학습 함수 (Focal Loss 및 IoU 적용)\n",
    "def train_unet_model_with_focal_loss(\n",
    "    x_train, y_train, x_val, y_val, batch_size=4, epochs=10, image_size=(512, 512), weight=1.0):\n",
    "    \"\"\"\n",
    "    U-Net 모델을 학습하는 함수입니다. 데이터 증강 및 Focal Loss를 적용합니다.\n",
    "    \n",
    "    매개변수:\n",
    "    - x_train, y_train: 학습 데이터와 레이블.\n",
    "    - x_val, y_val: 검증 데이터와 레이블.\n",
    "    - batch_size (int): 배치 크기.\n",
    "    - epochs (int): 학습 에포크 수.\n",
    "    - image_size (tuple): 이미지 크기.\n",
    "    - weight (float): Focal Loss 가중치.\n",
    "    \"\"\"\n",
    "    # U-Net 모델 초기화\n",
    "    model = unet_model(input_shape=(image_size[0], image_size[1], 1))\n",
    "\n",
    "    # 모델 컴파일 (Focal Loss 사용)\n",
    "    model = compile_model_with_focal_loss(model, weight=weight)\n",
    "\n",
    "    # EarlyStopping 콜백 설정\n",
    "    early_stopping = early_stopping_iou_callback(weight=weight)\n",
    "\n",
    "    # 데이터 증강\n",
    "    train_generator = augment_data(x_train, y_train)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        train_generator,                # 증강된 학습 데이터 사용\n",
    "        validation_data=(x_val, y_val), # 검증 데이터\n",
    "        epochs=epochs,                  # 학습 에포크 수\n",
    "        callbacks=[early_stopping]      # EarlyStopping 콜백\n",
    "    )\n",
    "\n",
    "    # 학습 로그 분석\n",
    "    analyze_logs(history)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# 로그 분석 함수\n",
    "def analyze_logs(history):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    train_iou = history.history['weighted_iou']\n",
    "    val_iou = history.history['val_weighted_iou']\n",
    "\n",
    "    print(\"\\n--- 학습 로그 분석 ---\\n\")\n",
    "    print(f\"최소 학습 손실: {min(train_loss):.4f} (에포크 {train_loss.index(min(train_loss)) + 1})\")\n",
    "    print(f\"최소 검증 손실: {min(val_loss):.4f} (에포크 {val_loss.index(min(val_loss)) + 1})\")\n",
    "    print(f\"최대 학습 정확도: {max(train_accuracy):.4f} (에포크 {train_accuracy.index(max(train_accuracy)) + 1})\")\n",
    "    print(f\"최대 검증 정확도: {max(val_accuracy):.4f} (에포크 {val_accuracy.index(max(val_accuracy)) + 1})\")\n",
    "    print(f\"최대 학습 IoU: {max(train_iou):.4f} (에포크 {train_iou.index(max(train_iou)) + 1})\")\n",
    "    print(f\"최대 검증 IoU: {max(val_iou):.4f} (에포크 {val_iou.index(max(val_iou)) + 1})\")\n",
    "\n",
    "    if val_loss[-1] > val_loss[val_loss.index(min(val_loss))]:\n",
    "        print(\"\\n경고: 검증 손실이 다시 증가하고 있습니다. 과적합 가능성을 확인하세요.\\n\")\n",
    "\n",
    "    # 손실 및 IoU 그래프 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_iou, label='Train IoU')\n",
    "    plt.plot(val_iou, label='Validation IoU')\n",
    "    plt.legend()\n",
    "    plt.title('IoU Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cac052",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model, history = train_unet_model_with_focal_loss(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    weight=2.0\n",
    ")\n",
    "analyze_logs(history)\n",
    "main_display_result(history, model, x_val, y_val, num_images=5, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23406914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
